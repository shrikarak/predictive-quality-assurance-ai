{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Pipeline for Predictive Quality Assurance in Manufacturing\n",
    "\n",
    "**Copyright (c) 2026 Shrikara Kaudambady. All rights reserved.**\n",
    "\n",
    "This notebook implements a multi-modal AI pipeline for quality assurance. The system analyzes both **image data** (a picture of a part) and **sensor data** (from the manufacturing process) to detect defects. It then automatically generates a natural language diagnostic report for the repair team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Simulation\n",
    "We'll generate a synthetic dataset. Each 'part' will have an ID, sensor readings, an image, and a label ('OK' or 'Defective'). Defective parts will have anomalies in both their sensor data and their image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_data(n_samples=1000, img_size=64):\n",
    "    np.random.seed(42)\n",
    "    data = []\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        part_id = f\"PART-{i:04d}\"\n",
    "        is_defective = np.random.rand() > 0.8 # 20% defective rate\n",
    "        \n",
    "        # Generate Sensor Data\n",
    "        if is_defective:\n",
    "            temp = np.random.normal(250, 15) # Higher temp for defects\n",
    "            pressure = np.random.normal(105, 5)\n",
    "            vibration = np.random.normal(40, 8) # Higher vibration for defects\n",
    "            label = 1\n",
    "        else:\n",
    "            temp = np.random.normal(220, 5)\n",
    "            pressure = np.random.normal(100, 2)\n",
    "            vibration = np.random.normal(20, 2)\n",
    "            label = 0\n",
    "        \n",
    "        data.append({'part_id': part_id, 'temperature': temp, 'pressure': pressure, 'vibration': vibration})\n",
    "        labels.append(label)\n",
    "        \n",
    "        # Generate Image Data\n",
    "        image = np.ones((img_size, img_size, 1)) * 0.5 + np.random.normal(0, 0.02, (img_size, img_size, 1))\n",
    "        if is_defective:\n",
    "            # Add a 'crack' to the image\n",
    "            x1, y1 = np.random.randint(10, img_size-10, 2)\n",
    "            x2, y2 = x1 + np.random.randint(-15, 15), y1 + np.random.randint(15, 25)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 0), 1) # Using cv2 notation for simplicity\n",
    "        images.append(np.clip(image, 0, 1))\n",
    "        \n",
    "    return pd.DataFrame(data), np.array(images), np.array(labels)\n",
    "\n",
    "# A simple line drawing function to avoid a full OpenCV dependency for the notebook\n",
    "def cv2_line_mock(img, pt1, pt2, color, thickness):\n",
    "    from skimage.draw import line\n",
    "    rr, cc = line(pt1[1], pt1[0], pt2[1], pt2[0])\n",
    "    img[rr, cc] = color[0]\n",
    "    return img\n",
    "cv2.line = cv2_line_mock\n",
    "\n",
    "\n",
    "df_sensors, images, labels = generate_qa_data()\n",
    "print(\"Data simulation complete.\")\n",
    "print(\"Sensor Data Shape:\", df_sensors.shape)\n",
    "print(\"Image Data Shape:\", images.shape)\n",
    "print(\"Labels Shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Vision Model (CNN)\n",
    "First, we train a simple CNN to classify images as 'OK' or 'Defective'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "vision_model = models.Sequential([\n",
    "    layers.Input(shape=(64, 64, 1)),\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "vision_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vision_model.fit(X_train_img, y_train_img, epochs=5, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Sensor Data Model (Random Forest)\n",
    "Next, we train a Random Forest model on the tabular sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sensors = df_sensors[['temperature', 'pressure', 'vibration']]\n",
    "X_train_sens, X_test_sens, y_train_sens, y_test_sens = train_test_split(X_sensors, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "sensor_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "sensor_model.fit(X_train_sens, y_train_sens)\n",
    "print(\"Sensor model training complete.\")\n",
    "print(\"Sensor Model Accuracy:\", sensor_model.score(X_test_sens, y_test_sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build the Full QA Pipeline with Report Generation\n",
    "Now we create a class that encapsulates both models and contains the logic to fuse their results and generate a diagnostic report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityAssurancePipeline:\n",
    "    def __init__(self, vision_model, sensor_model):\n",
    "        self.vision_model = vision_model\n",
    "        self.sensor_model = sensor_model\n",
    "    \n",
    "    def _generate_report(self, part_id, vision_pred, sensor_pred):\n",
    "        vision_status = \"Defect Detected\" if vision_pred > 0.5 else \"OK\"\n",
    "        sensor_status = \"Anomaly Detected\" if sensor_pred == 1 else \"OK\"\n",
    "        \n",
    "        # Fusion Logic\n",
    "        if vision_status == \"Defect Detected\":\n",
    "            final_status = \"REJECTED\"\n",
    "            notes = \"A visual defect (crack) was identified by the vision system.\"\n",
    "            action = \"Route part to manual inspection and repair station.\"\n",
    "        elif sensor_status == \"Anomaly Detected\":\n",
    "            final_status = \"FLAGGED FOR REVIEW\"\n",
    "            notes = \"Sensor data showed anomalies during production. No visual defect was found, but part may have internal stress.\"\n",
    "            action = \"Route part to advanced screening (e.g., X-ray). Monitor production machine for calibration issues.\"\n",
    "        else:\n",
    "            final_status = \"APPROVED\"\n",
    "            notes = \"No issues detected by vision or sensor models.\"\n",
    "            action = \"Proceed to next manufacturing step.\"\n",
    "            \n",
    "        # Template-based Natural Language Generation\n",
    "        report = f\"\"\"\n",
    "        *** AUTOMATED QA REPORT ***\n",
    "        --------------------------------------------------\n",
    "        PART ID:         {part_id}\n",
    "        TIMESTAMP:       {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "        \n",
    "        FINAL STATUS:    {final_status}\n",
    "        --------------------------------------------------\n",
    "        EVIDENCE:\n",
    "        - Vision System:   {vision_status}\n",
    "        - Sensor System:   {sensor_status}\n",
    "        \n",
    "        NOTES:           {notes}\n",
    "        \n",
    "        RECOMMENDED ACTION: {action}\n",
    "        --------------------------------------------------\n",
    "        \"\"\"\n",
    "        return report\n",
    "\n",
    "    def analyze_part(self, part_id, image_data, sensor_data):\n",
    "        # Ensure data is in the correct format\n",
    "        image_input = np.expand_dims(image_data, axis=0) # Add batch dimension\n",
    "        sensor_input = sensor_data.values.reshape(1, -1) # Reshape for single prediction\n",
    "        \n",
    "        # Get predictions from both models\n",
    "        vision_prediction = self.vision_model.predict(image_input)[0][0]\n",
    "        sensor_prediction = self.sensor_model.predict(sensor_input)[0]\n",
    "        \n",
    "        # Generate the final report\n",
    "        report = self._generate_report(part_id, vision_prediction, sensor_prediction)\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run Demonstration\n",
    "Let's test the full pipeline on a defective part and a normal part from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline with our trained models\n",
    "qa_pipeline = QualityAssurancePipeline(vision_model, sensor_model)\n",
    "\n",
    "# --- Scenario 1: Analyze a DEFECTIVE part ---\n",
    "defective_idx = np.where(y_test_img == 1)[0][0]\n",
    "part_id_defective = df_sensors.loc[X_test_sens.index[defective_idx], 'part_id']\n",
    "image_defective = X_test_img[defective_idx]\n",
    "sensors_defective = X_test_sens.iloc[defective_idx]\n",
    "\n",
    "qa_pipeline.analyze_part(part_id_defective, image_defective, sensors_defective)\n",
    "\n",
    "# --- Scenario 2: Analyze a NORMAL part ---\n",
    "normal_idx = np.where(y_test_img == 0)[0][0]\n",
    "part_id_normal = df_sensors.loc[X_test_sens.index[normal_idx], 'part_id']\n",
    "image_normal = X_test_img[normal_idx]\n",
    "sensors_normal = X_test_sens.iloc[normal_idx]\n",
    "\n",
    "qa_pipeline.analyze_part(part_id_normal, image_normal, sensors_normal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
